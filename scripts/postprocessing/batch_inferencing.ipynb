{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75d5045c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a10bc51f8164fc9893e04713aca0d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fb9e4898324830a434606761bad413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TwoTowerModel(\n",
       "  (user_tower): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.28872460017670404, inplace=False)\n",
       "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (content_tower): Sequential(\n",
       "    (0): Linear(in_features=132, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.28872460017670404, inplace=False)\n",
       "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------\n",
    "# Parameters\n",
    "# ---------------------\n",
    "best_run_id = \"8408fd846c784f55a402b3be6bace2aa\"\n",
    "custom_mlflow_path = \"../training/mlruns\"\n",
    "user_emb_path = \"user_embeddings.pt\"\n",
    "content_emb_path = \"content_embeddings.pt\"\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(f\"file://{os.path.abspath(custom_mlflow_path)}\")\n",
    "\n",
    "# ---------------------\n",
    "# Load model\n",
    "# ---------------------\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval()  # eval mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "36ba237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully from pickle\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation data using pickle\n",
    "\n",
    "with open(\"../preprocessing/train_val_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "tX_user = data[\"tX_user\"]\n",
    "tX_content = data[\"tX_content\"]\n",
    "ty = data[\"ty\"]\n",
    "vX_user = data[\"vX_user\"]\n",
    "vX_content = data[\"vX_content\"]\n",
    "vy = data[\"vy\"]\n",
    "processed_users = data[\"processed_users\"]\n",
    "test_content = data[\"test_content\"]\n",
    "\n",
    "print(\"✅ Data loaded successfully from pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "51503441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x):\n",
    "    if torch.is_tensor(x):\n",
    "        return x.float()\n",
    "    elif hasattr(x, \"values\"):\n",
    "        return torch.tensor(x.values, dtype=torch.float32)\n",
    "    else:\n",
    "        return torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afad290",
   "metadata": {},
   "source": [
    "# ---------------------\n",
    "# Compute User Embeddings\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0582cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_user_embeddings(user_df, save_path=user_emb_path):\n",
    "    # Split IDs and features\n",
    "    user_tensor = user_df.values\n",
    "    device_ids = user_tensor[:, 0].astype(str)\n",
    "    features = to_tensor(user_tensor[:, 1:].astype('float'))\n",
    "\n",
    "    # Compute embeddings\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        user_emb = model.user_tower(features)\n",
    "\n",
    "    # Create mapping {device_id: embedding_tensor}\n",
    "    user_emb_dict = {did: emb for did, emb in zip(device_ids, user_emb)}\n",
    "\n",
    "    # Save as dictionary\n",
    "    torch.save(user_emb_dict, save_path)\n",
    "    print(f\"✅ Saved {len(user_emb_dict)} user embeddings to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c57457cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 10400 user embeddings to user_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "compute_and_save_user_embeddings(processed_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8837db4f",
   "metadata": {},
   "source": [
    "# ---------------------\n",
    "# Compute Content Embeddings\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc91a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_content_embeddings(content_df, save_path=content_emb_path):\n",
    "    # Split IDs and features\n",
    "    content_tensor = content_df.values\n",
    "    hash_ids = content_tensor[:, 0]#.astype(str)\n",
    "    features = to_tensor(content_tensor[:, 1:].astype('float'))\n",
    "\n",
    "    # Compute embeddings\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        content_emb = model.content_tower(features)\n",
    "\n",
    "    # Create mapping {hash_id: embedding_tensor}\n",
    "    content_emb_dict = {hid: emb for hid, emb in zip(hash_ids, content_emb)}\n",
    "\n",
    "    # Save as dictionary\n",
    "    torch.save(content_emb_dict, save_path)\n",
    "    print(f\"✅ Saved {len(content_emb_dict)} content embeddings to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "be37f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 970 content embeddings to content_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "compute_and_save_content_embeddings(test_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112dde6",
   "metadata": {},
   "source": [
    "# ---------------------\n",
    "# Predict from Embeddings\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_embeddings(user_emb, content_emb):\n",
    "    with torch.no_grad():\n",
    "        combined = torch.cat([user_emb, content_emb], dim=1)\n",
    "        preds = model.output_layer(combined).squeeze(-1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f3db3",
   "metadata": {},
   "source": [
    "# ---------------------\n",
    "# Load Embeddings\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ed4761ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb_dict = torch.load(user_emb_path, weights_only=False)\n",
    "content_emb_dict = torch.load(content_emb_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f8c01545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49e85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Users: 100%|██████████| 10400/10400 [02:33<00:00, 67.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Compute top 50 for each user ---\n",
    "results = []\n",
    "\n",
    "for user_id, user_emb in tqdm(user_emb_dict.items(), desc=\"Users\", total=len(user_emb_dict)):\n",
    "    scores = []\n",
    "    for hashid, content_emb in content_emb_dict.items():\n",
    "        # Compute prediction score\n",
    "        score = predict_from_embeddings(user_emb.reshape(1, -1), content_emb.reshape(1, -1))\n",
    "        scores.append((hashid, score))\n",
    "\n",
    "    # Sort by score (descending) and take top 50\n",
    "    top_50 = sorted(scores, key=lambda x: x[1], reverse=True)[:50]\n",
    "\n",
    "    for rank, (hashid, score) in enumerate(top_50, 1):\n",
    "        results.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"hashid\": hashid,\n",
    "            \"rank\": rank,\n",
    "            \"score\": score\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "827df6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved top 50 recommendations for each user to user_top50_recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Convert to DataFrame ---\n",
    "df_top50 = pd.DataFrame(results)\n",
    "df_top50.to_csv(\"user_top50_recommendations.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved top 50 recommendations for each user to user_top50_recommendations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf1d2523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>hashid</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197b123e-eb9e-4fc1-a32d-aa86aaea425e</td>\n",
       "      <td>z4xtyyjz-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.3298)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197b123e-eb9e-4fc1-a32d-aa86aaea425e</td>\n",
       "      <td>s3nxsntx-1</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.3298)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197b123e-eb9e-4fc1-a32d-aa86aaea425e</td>\n",
       "      <td>p18jiu5f-1</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.3298)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197b123e-eb9e-4fc1-a32d-aa86aaea425e</td>\n",
       "      <td>s98imoxc-1</td>\n",
       "      <td>4</td>\n",
       "      <td>[tensor(0.3298)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197b123e-eb9e-4fc1-a32d-aa86aaea425e</td>\n",
       "      <td>kc3pd7h5-1</td>\n",
       "      <td>5</td>\n",
       "      <td>[tensor(0.3297)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519995</th>\n",
       "      <td>017120da-5a11-4139-a438-97906a941a46</td>\n",
       "      <td>xy3xvzre-1</td>\n",
       "      <td>46</td>\n",
       "      <td>[tensor(0.3222)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519996</th>\n",
       "      <td>017120da-5a11-4139-a438-97906a941a46</td>\n",
       "      <td>xq2dhwal-1</td>\n",
       "      <td>47</td>\n",
       "      <td>[tensor(0.3222)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519997</th>\n",
       "      <td>017120da-5a11-4139-a438-97906a941a46</td>\n",
       "      <td>0zesqner-1</td>\n",
       "      <td>48</td>\n",
       "      <td>[tensor(0.3222)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519998</th>\n",
       "      <td>017120da-5a11-4139-a438-97906a941a46</td>\n",
       "      <td>4v32qsjt-1</td>\n",
       "      <td>49</td>\n",
       "      <td>[tensor(0.3221)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519999</th>\n",
       "      <td>017120da-5a11-4139-a438-97906a941a46</td>\n",
       "      <td>s0hjdvff-1</td>\n",
       "      <td>50</td>\n",
       "      <td>[tensor(0.3221)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     user_id      hashid  rank  \\\n",
       "0       197b123e-eb9e-4fc1-a32d-aa86aaea425e  z4xtyyjz-1     1   \n",
       "1       197b123e-eb9e-4fc1-a32d-aa86aaea425e  s3nxsntx-1     2   \n",
       "2       197b123e-eb9e-4fc1-a32d-aa86aaea425e  p18jiu5f-1     3   \n",
       "3       197b123e-eb9e-4fc1-a32d-aa86aaea425e  s98imoxc-1     4   \n",
       "4       197b123e-eb9e-4fc1-a32d-aa86aaea425e  kc3pd7h5-1     5   \n",
       "...                                      ...         ...   ...   \n",
       "519995  017120da-5a11-4139-a438-97906a941a46  xy3xvzre-1    46   \n",
       "519996  017120da-5a11-4139-a438-97906a941a46  xq2dhwal-1    47   \n",
       "519997  017120da-5a11-4139-a438-97906a941a46  0zesqner-1    48   \n",
       "519998  017120da-5a11-4139-a438-97906a941a46  4v32qsjt-1    49   \n",
       "519999  017120da-5a11-4139-a438-97906a941a46  s0hjdvff-1    50   \n",
       "\n",
       "                   score  \n",
       "0       [tensor(0.3298)]  \n",
       "1       [tensor(0.3298)]  \n",
       "2       [tensor(0.3298)]  \n",
       "3       [tensor(0.3298)]  \n",
       "4       [tensor(0.3297)]  \n",
       "...                  ...  \n",
       "519995  [tensor(0.3222)]  \n",
       "519996  [tensor(0.3222)]  \n",
       "519997  [tensor(0.3222)]  \n",
       "519998  [tensor(0.3221)]  \n",
       "519999  [tensor(0.3221)]  \n",
       "\n",
       "[520000 rows x 4 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63028f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
