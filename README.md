ğŸš€ Overview

INS_E2E_RecSys is a production-grade recommendation system built using the Two-Tower (Dual Encoder) architecture, demonstrating a full MLOps workflow.

It combines preprocessing, training, inferencing , API deployment, jenkins orchestration and respective pipelines using industry-standard tools like MLflow, Prefect, and Jenkins.

While the model architecture is intentionally kept simple for demonstration, the pipeline structure and orchestration mimic real-world production systems.

ğŸ¯ Table of Content

1. EDA
2. Pre-Processing
3. Model Training
4. Post-Processing
5. Evaluation
6. Deployment


What is project about?

Problem Statement: Build a Two-Tower Recommendation System that: Learns user and content embeddings separately. Computes similarity scores to recommend top-K content per user.

ğŸ’¼ Business Problem : Personalized recommendations drive engagement, retention, and revenue. This project demonstrates how an organization can:


How does everything work ?

Jenkins: Use for build, Create docker container, run pytest, lint check
Docker: Docker container is pushed to public repository which can be pulled in AWS sagemaker for running the image.
Terraform: use to setup the infrastucture
AWS Sagemaker: Jenkins upsets 3 pipeline which can be triggered from sagemaker studios.

How to install?

ğŸ§© Prerequisites

Jenkins, Docker, AWS Account (optional â€“ can also be tested locally)

ğŸ’» Recommended Setup
IDE: Visual Studio Code, Python Version: 3.10.13

Run the following commands Environemnt Setup

``` bash
    conda create -n venv python=3.10.13 -y
    conda activate venv
    git clone https://github.com/erYash15/INS_E2E_RecSys.git
    cd INS_E2E_RecSys
    pip install -r requirements.txt
    python -m pip show torch
```


âš™ï¸ How to Run

Locally

Preprocessing â€“ Handles encoding, feature transformations, and missing data, save artifacts.
Model Training â€“ Implements a Two-Tower model using PyTorch.
Post-Processing â€“ Generates and stores top-K recommendations.


``` python
    python -m scripts.preprocessing.preprocessing
    python -m scripts.training.two_tower
```



Evaluation â€“ Computes metrics like Hit@K, NDCG@K, and MAP.






Pipeline Orchestration â€“ Managed by Prefect and Jenkins.


Conclusion:
The Two-Tower model offers the best trade-off between scalability, simplicity, and performance, making it ideal for real-world recommender systems.

ğŸ”§ Technologies Used
Category	Tools
Language	Python 3.10
Frameworks	PyTorch, Scikit-learn
Pipeline Orchestration	Prefect
Automation & CI/CD	Jenkins
Experiment Tracking	MLflow
Visualization	Matplotlib, Seaborn
Environment Management	pyenv, virtualenv
Deployment Simulation	SageMaker Local Mode
ğŸ§® Evaluation Metrics

Hit@K â€“ Measures whether relevant items appear in the top-K list.

NDCG@K â€“ Captures ranking quality considering position.

MAP (Mean Average Precision) â€“ Averages precision across users.

ğŸ§  Pipeline Flow

Prefect Pipeline (flow.py)

Loads raw data â†’ preprocesses â†’ trains model â†’ logs metrics.

Jenkins Orchestration

Automates the Prefect flow on commits or nightly runs.

MLflow Tracking

Logs hyperparameters, metrics, and models for every experiment.

Post-processing

Generates top-K recommendations and stores artifacts.

Deployment

Uses SageMaker local simulation or can easily extend to AWS deployment.

ğŸ–¥ï¸ MLflow UI

To visualize runs, metrics, and models:

cd artifacts
mlflow ui


Then open your browser and navigate to:

http://127.0.0.1:5000

Youâ€™ll see:

Trial details (0th, 1st, â€¦)

Hyperparameters

Training & validation loss curves

Complete trial list with performance comparisons.

ğŸ§° How to Run
1ï¸âƒ£ Create Environment
pyenv virtualenv 3.10.13 ins_venv
pyenv activate ins_venv
pip install -r requirements.txt

2ï¸âƒ£ Run Prefect Pipeline
python flows/train_pipeline.py

3ï¸âƒ£ Trigger from Jenkins

Configure Jenkins job with:

python flows/train_pipeline.py

4ï¸âƒ£ Launch MLflow UI
mlflow ui --port 5000

ğŸ“¦ Directory Structure
INS_E2E_RecSys/
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ experiments/*
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ prep_utils.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ two_tower_utils.py
â”‚   â”‚   â””â”€â”€ two_tower.py
â”‚   â””â”€â”€ postprocessing/
â”‚       â””â”€â”€ evaluation.py
â”‚       â””â”€â”€ batchinference.py
â”‚       â””â”€â”€ batchinference.py
â”‚
â”œâ”€â”€ flows/
â”‚   â””â”€â”€ train_pipeline.py
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ user_encoders/
â”‚   â”œâ”€â”€ content_encoders/
â”‚   â””â”€â”€ mlruns/
â”‚
â”œâ”€â”€ experiments/
â”‚
â”œâ”€â”€ Jenkinsfile
â””â”€â”€ README.md

ğŸ§© Future Improvements

Add transformer-based hybrid retrieval.

Integrate feature store (e.g., Feast).

Support for online A/B testing.

Optimize for real-time recommendations.

ğŸ—“ï¸ Author

Yash Gupta
Data Scientist | MLOps Enthusiast | Forecasting & Recommendation Systems

Would you like me to also generate a PowerPoint summary (3â€“4 slides) from this README (Problem â†’ Approach â†’ Architecture â†’ Results)? Itâ€™ll be perfect for presentation/demo.
